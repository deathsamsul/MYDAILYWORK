{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c90b44-ee53-4a67-a0bf-aced3a767914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ------------\n",
      "absl-py                      2.1.0\n",
      "accelerate                   0.30.1\n",
      "aiohappyeyeballs             2.6.1\n",
      "aiohttp                      3.13.3\n",
      "aiosignal                    1.4.0\n",
      "altair                       5.5.0\n",
      "annotated-types              0.7.0\n",
      "anyio                        4.6.2\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "asttokens                    2.0.5\n",
      "astunparse                   1.6.3\n",
      "async-timeout                5.0.1\n",
      "attrs                        24.3.0\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.12.3\n",
      "bleach                       6.2.0\n",
      "blinker                      1.9.0\n",
      "Bottleneck                   1.4.2\n",
      "Brotli                       1.0.9\n",
      "cachetools                   5.5.1\n",
      "catboost                     1.2.8\n",
      "category-encoders            2.6.4\n",
      "certifi                      2025.1.31\n",
      "cffi                         1.17.1\n",
      "charset-normalizer           3.4.1\n",
      "click                        8.1.8\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.1\n",
      "contourpy                    1.2.1\n",
      "cycler                       0.11.0\n",
      "datasets                     2.19.1\n",
      "debugpy                      1.8.11\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "dill                         0.3.8\n",
      "entrypoints                  0.4\n",
      "exceptiongroup               1.2.0\n",
      "executing                    0.8.3\n",
      "fastjsonschema               2.20.0\n",
      "filelock                     3.19.1\n",
      "flatbuffers                  25.1.24\n",
      "fonttools                    4.55.3\n",
      "frozenlist                   1.8.0\n",
      "fsspec                       2024.3.1\n",
      "gast                         0.4.0\n",
      "gitdb                        4.0.12\n",
      "GitPython                    3.1.45\n",
      "google-auth                  2.38.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "graphviz                     0.21\n",
      "grpcio                       1.70.0\n",
      "h11                          0.16.0\n",
      "h5py                         3.12.1\n",
      "hf-xet                       1.2.0\n",
      "httpcore                     1.0.9\n",
      "httpx                        0.28.1\n",
      "huggingface-hub              0.23.2\n",
      "idna                         3.10\n",
      "imbalanced-learn             0.12.4\n",
      "importlib_metadata           8.5.0\n",
      "importlib_resources          6.4.0\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.15.0\n",
      "ipython-genutils             0.2.0\n",
      "jedi                         0.19.2\n",
      "Jinja2                       3.1.5\n",
      "joblib                       1.4.2\n",
      "jsonpatch                    1.33\n",
      "jsonpointer                  3.0.0\n",
      "jsonschema                   4.23.0\n",
      "jsonschema-specifications    2023.7.1\n",
      "jupyter_client               7.4.9\n",
      "jupyter_core                 5.7.2\n",
      "jupyter-events               0.10.0\n",
      "jupyter_server               2.14.1\n",
      "jupyter_server_terminals     0.4.4\n",
      "jupyterlab-pygments          0.2.2\n",
      "keras                        2.10.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "kiwisolver                   1.4.4\n",
      "langchain-core               0.3.83\n",
      "langchain-huggingface        0.3.1\n",
      "langsmith                    0.4.37\n",
      "libclang                     18.1.1\n",
      "lightgbm                     4.6.0\n",
      "Markdown                     3.7\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.9.2\n",
      "matplotlib-inline            0.1.6\n",
      "mistune                      2.0.4\n",
      "mkl_fft                      1.3.11\n",
      "mkl_random                   1.2.8\n",
      "mkl-service                  2.4.0\n",
      "mpmath                       1.3.0\n",
      "multidict                    6.7.1\n",
      "multiprocess                 0.70.16\n",
      "narwhals                     2.12.0\n",
      "nb_conda                     2.2.1\n",
      "nb_conda_kernels             2.5.2\n",
      "nbclassic                    1.1.0\n",
      "nbclient                     0.8.0\n",
      "nbconvert                    7.16.4\n",
      "nbformat                     5.10.4\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.2.1\n",
      "notebook                     6.5.7\n",
      "notebook_shim                0.2.3\n",
      "numexpr                      2.10.1\n",
      "numpy                        1.23.3\n",
      "oauthlib                     3.2.2\n",
      "opt_einsum                   3.4.0\n",
      "orjson                       3.11.5\n",
      "overrides                    7.4.0\n",
      "packaging                    24.2\n",
      "pandas                       2.2.3\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.4\n",
      "patsy                        1.0.2\n",
      "pickleshare                  0.7.5\n",
      "pillow                       11.1.0\n",
      "pip                          25.0\n",
      "platformdirs                 3.10.0\n",
      "plotly                       6.5.0\n",
      "prometheus_client            0.21.0\n",
      "prompt-toolkit               3.0.43\n",
      "propcache                    0.4.1\n",
      "protobuf                     3.19.6\n",
      "psutil                       5.9.0\n",
      "pure-eval                    0.2.2\n",
      "pyarrow                      21.0.0\n",
      "pyarrow-hotfix               0.7\n",
      "pyasn1                       0.6.1\n",
      "pyasn1_modules               0.4.1\n",
      "pycparser                    2.21\n",
      "pydantic                     2.12.5\n",
      "pydantic_core                2.41.5\n",
      "pydeck                       0.9.1\n",
      "Pygments                     2.15.1\n",
      "pyparsing                    3.2.0\n",
      "python-dateutil              2.9.0.post0\n",
      "python-json-logger           3.2.1\n",
      "pytz                         2024.1\n",
      "pywin32                      308\n",
      "pywinpty                     2.0.14\n",
      "PyYAML                       6.0.2\n",
      "pyzmq                        24.0.1\n",
      "referencing                  0.30.2\n",
      "regex                        2026.1.15\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            2.0.0\n",
      "requests-toolbelt            1.0.0\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rpds-py                      0.22.3\n",
      "rsa                          4.9\n",
      "safetensors                  0.7.0\n",
      "scikit-learn                 1.6.1\n",
      "scipy                        1.13.1\n",
      "seaborn                      0.13.2\n",
      "Send2Trash                   1.8.2\n",
      "sentence-transformers        5.1.2\n",
      "sentencepiece                0.2.1\n",
      "setuptools                   75.8.0\n",
      "shellingham                  1.5.4\n",
      "six                          1.16.0\n",
      "smmap                        5.0.2\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.5\n",
      "stack-data                   0.2.0\n",
      "statsmodels                  0.14.5\n",
      "streamlit                    1.50.0\n",
      "sympy                        1.13.1\n",
      "tenacity                     9.1.2\n",
      "tensorboard                  2.10.1\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.10.1\n",
      "tensorflow-estimator         2.10.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.5.0\n",
      "terminado                    0.17.1\n",
      "threadpoolctl                3.5.0\n",
      "tinycss2                     1.4.0\n",
      "tokenizers                   0.19.1\n",
      "toml                         0.10.2\n",
      "torch                        2.5.1+cu121\n",
      "torchaudio                   2.5.1+cu121\n",
      "torchvision                  0.20.1+cu121\n",
      "tornado                      6.4.2\n",
      "tqdm                         4.67.3\n",
      "traitlets                    5.14.3\n",
      "transformers                 4.41.2\n",
      "typer-slim                   0.21.1\n",
      "typing_extensions            4.15.0\n",
      "typing-inspection            0.4.2\n",
      "tzdata                       2023.3\n",
      "unicodedata2                 15.1.0\n",
      "urllib3                      2.3.0\n",
      "uuid_utils                   0.14.0\n",
      "watchdog                     6.0.0\n",
      "wcwidth                      0.2.5\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.8.0\n",
      "Werkzeug                     3.1.3\n",
      "wheel                        0.45.1\n",
      "wrapt                        1.17.2\n",
      "xgboost                      2.1.4\n",
      "xxhash                       3.6.0\n",
      "yarl                         1.22.0\n",
      "zipp                         3.21.0\n",
      "zstandard                    0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270aacf4-b15f-407e-9727-e10b2a963a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsu\\anaconda3\\envs\\tfp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee3b1d7-04d9-49fe-9bb3-f7b08227e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc1a261-94a9-4a99-bbf5-b39dddfcf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"movie_genre_train_data.txt\",\n",
    "    sep=\":::\",\n",
    "    engine=\"python\",\n",
    "    names=[\"id\", \"title\", \"genre\", \"summary\"]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932fb384-e07d-46f5-a93e-540d21bdd363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "documentary     3000\n",
      "short           3000\n",
      "drama           3000\n",
      "comedy          3000\n",
      "horror          2204\n",
      "thriller        1591\n",
      "action          1315\n",
      "western         1032\n",
      "reality-tv       884\n",
      "family           784\n",
      "adventure        775\n",
      "music            731\n",
      "romance          672\n",
      "sci-fi           647\n",
      "adult            590\n",
      "crime            505\n",
      "animation        498\n",
      "sport            432\n",
      "talk-show        391\n",
      "fantasy          323\n",
      "mystery          319\n",
      "musical          277\n",
      "biography        265\n",
      "history          243\n",
      "game-show        194\n",
      "news             181\n",
      "war              132\n",
      "Name: count, dtype: int64\n",
      "New total samples: 26985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsu\\AppData\\Local\\Temp\\ipykernel_15044\\451223140.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data.groupby(\"genre\")\n"
     ]
    }
   ],
   "source": [
    "max_per_class = 3000\n",
    "\n",
    "df = (\n",
    "    data.groupby(\"genre\")\n",
    "      .apply(lambda x: x.sample(min(len(x), max_per_class), random_state=42))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(df[\"genre\"].value_counts())\n",
    "print(\"New total samples:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcedd720-3206-4616-bbd0-00f9689bbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_genres(genre):\n",
    "\n",
    "    if genre in [\"history\", \"war\", \"biography\"]:\n",
    "        return \"historical\"\n",
    "    elif genre in [\"game-show\", \"talk-show\", \"news\"]:\n",
    "        return \"tv\"\n",
    "    elif genre in [\"fantasy\", \"animation\"]:\n",
    "        return \"fantasy\"\n",
    "    elif genre in [\"musical\", \"music\"]:\n",
    "        return \"music\"\n",
    "    elif genre in [\"crime\", \"mystery\"]:\n",
    "        return \"crime\"\n",
    "    else:\n",
    "        return genre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "271cb92d-d3f7-4497-8ac4-c3ad3885de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre']=df['genre'].str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33077dd3-18b3-4bff-9e3a-0cda65817218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genre\"] = df[\"genre\"].apply(merge_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef09450-0642-4139-af80-dedc2edce7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 26985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Total samples:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b70dc9-1d13-417c-9aef-087c57a403a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "documentary    3000\n",
       "short          3000\n",
       "comedy         3000\n",
       "drama          3000\n",
       "horror         2204\n",
       "thriller       1591\n",
       "action         1315\n",
       "western        1032\n",
       "music          1008\n",
       "reality-tv      884\n",
       "crime           824\n",
       "fantasy         821\n",
       "family          784\n",
       "adventure       775\n",
       "tv              766\n",
       "romance         672\n",
       "sci-fi          647\n",
       "historical      640\n",
       "adult           590\n",
       "sport           432\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f11edc-4a8e-4931-8158-35005ced6dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26985"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20214512-f207-47b0-809d-816cbe10b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df[\"text\"] = df[\"title\"].fillna(\"\") + \" \" + df[\"summary\"].fillna(\"\")\n",
    "        df[\"text\"] = df[\"text\"].str.strip()\n",
    "        return df[\"text\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b23dfe-471b-4c40-900a-b2a2beb9fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessing()\n",
    "df[\"text\"] = preprocessor.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6a069b-2654-4b6b-9733-fce461f18038",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc2c948-9dba-426a-87ce-7700f9a30630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 20\n"
     ]
    }
   ],
   "source": [
    "df[\"label\"] = label_encoder.fit_transform(df[\"genre\"])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(\"Number of classes:\", num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f043ea66-9c6d-43b0-bb89-86083c4a5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(df[\"label\"]),\n",
    "    y=df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e029b7fc-8fd0-4b8d-a800-1ffc8b369f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23b85247-bceb-4c8a-beeb-5a698938dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({\n",
    "    \"text\": df[\"text\"].tolist(),\n",
    "    \"label\": df[\"label\"].tolist()\n",
    "})\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede35371-ad6f-4c8c-bc33-e20b92e70e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# cache_dir = os.path.expanduser(\"~/.cache/huggingface\")\n",
    "# shutil.rmtree(cache_dir, ignore_errors=True)\n",
    "\n",
    "# print(\"Cache cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aabe492-48dd-4bcd-b2bc-5fef24fdaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f690cf17-5bb9-4d34-ac6c-e9105d4854f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27173bd-53a1-416c-9917-659051b48f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \\\n",
    "# transformers==4.41.2 \\\n",
    "# huggingface_hub==0.23.2 \\\n",
    "# tokenizers==0.19.1 \\\n",
    "# datasets==2.19.1 \\\n",
    "# accelerate==0.30.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2cc455-a748-418e-8b7e-c822cc49a5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feafe552-4d17-4d8e-968f-cbf9d261f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd7345b-1767-4220-bf71-7ac282a98d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24286/24286 [00:15<00:00, 1561.88 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2699/2699 [00:01<00:00, 1447.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset = dataset.remove_columns([\"text\"])\n",
    "dataset.set_format(\"torch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d978be35-ba20-4ba8-a026-766519e2afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "124dbdd0-0cf8-4242-a068-c32673b56fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs[\"labels\"]\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[\"logits\"]\n",
    "\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(\n",
    "            weight=class_weights\n",
    "        )\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69fb2b0a-4690-4e15-b6f0-d60e2874b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71bd615d-000d-4d1d-8145-5e266148de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsu\\anaconda3\\envs\\tfp\\lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,   \n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,                      \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    logging_steps=50,\n",
    "    report_to=[]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c50f496-c036-4199-8776-2dd77af5adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsu\\anaconda3\\envs\\tfp\\lib\\site-packages\\accelerate\\accelerator.py:479: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c569500-dc41-4c8d-9051-3fc22a1a5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04a86d7e-09b0-4e61-98bc-fe0e34c40a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4551' max='4551' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4551/4551 1:51:52, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.592500</td>\n",
       "      <td>1.536625</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.486155</td>\n",
       "      <td>0.508719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.244400</td>\n",
       "      <td>1.388453</td>\n",
       "      <td>0.580956</td>\n",
       "      <td>0.555011</td>\n",
       "      <td>0.580700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.004300</td>\n",
       "      <td>1.383200</td>\n",
       "      <td>0.585402</td>\n",
       "      <td>0.553894</td>\n",
       "      <td>0.582310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4551, training_loss=1.4884355951471397, metrics={'train_runtime': 6716.4808, 'train_samples_per_second': 10.848, 'train_steps_per_second': 0.678, 'total_flos': 4306187702135088.0, 'train_loss': 1.4884355951471397, 'epoch': 2.9982706085810755})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eda86cdb-8952-42d0-b310-2a85d7a86af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ GPU Training Completed Successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.save_model(\"deberta_movie_genre_model_gpu_v1\")\n",
    "tokenizer.save_pretrained(\"deberta_movie_genre_model_gpu_v1\")\n",
    "\n",
    "print(\"ðŸš€ GPU Training Completed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "174b669e-9e93-4aaa-8e27-c26e59fa66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e4a57e5-ad55-4f4d-ad5a-bec21cf5377c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_movie_genre_model_gpu_v1.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_encoder,'label_encoder_movie_genre_model_gpu_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf6ad3a5-b269-452b-bff4-d077ee78cf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3884531259536743, 'eval_accuracy': 0.5809559095961467, 'eval_f1_macro': 0.5550109319001181, 'eval_f1_weighted': 0.5807000930423225, 'eval_runtime': 59.777, 'eval_samples_per_second': 45.151, 'eval_steps_per_second': 22.584, 'epoch': 2.9982706085810755}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4f3ea7a6-be18-499f-a29b-94353e59b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('movie_genre_test_data.txt',sep=':::',engine='python',names=['id','title','genre','summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a41e98d9-4291-4f0b-9dda-5317254a2393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>7723</td>\n",
       "      <td>Aranyer Din Ratri (1970)</td>\n",
       "      <td>drama</td>\n",
       "      <td>A group of four middle class workers in India...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>3190</td>\n",
       "      <td>Giorni e nuvole (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Manager Michele lost his job but didn't tell ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       title    genre  \\\n",
       "7722  7723   Aranyer Din Ratri (1970)    drama    \n",
       "3189  3190     Giorni e nuvole (2007)    drama    \n",
       "\n",
       "                                                summary  \n",
       "7722   A group of four middle class workers in India...  \n",
       "3189   Manager Michele lost his job but didn't tell ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7aa6a16b-fa34-419f-a388-916d25dead9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test.iloc[0:13]\n",
    "y_test=test['genre'].iloc[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "465f7b6e-2d68-4f04-8c07-a4a63e3939d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsu\\AppData\\Local\\Temp\\ipykernel_15044\\1635970356.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test.drop(['title','genre'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "x_test.drop(['title','genre'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5638de8-2daa-44ed-9953-0ab1b10f3902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         thriller \n",
       "1           comedy \n",
       "2      documentary \n",
       "3            drama \n",
       "4            drama \n",
       "5           horror \n",
       "6            drama \n",
       "7           comedy \n",
       "8      documentary \n",
       "9            drama \n",
       "10           drama \n",
       "11           drama \n",
       "12           drama \n",
       "Name: genre, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5c90606-bf9f-40c5-87a7-d969344af6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "text = \"A detective investigates a mysterious murder.\"\n",
    "\n",
    "predict_dataset = Dataset.from_dict({\n",
    "    \"text\": [text]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54b49a47-b0cb-4e5a-a303-3e813bf712a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "predict_dataset = predict_dataset.map(tokenize_function, batched=True)\n",
    "predict_dataset = predict_dataset.remove_columns([\"text\"])\n",
    "predict_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c58fa49-01e9-4b2f-a43f-69943bd2ee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class id: 4\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(predict_dataset)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pred_class = np.argmax(predictions.predictions, axis=1)[0]\n",
    "\n",
    "print(\"Predicted class id:\", pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b74d42b-e6be-4113-91f9-a896a17da8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def predict_genre(summary_text):\n",
    "    inputs = tokenizer(\n",
    "        summary_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    predicted_class_id = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return label_classes[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0587541-f02b-41df-99ce-63feae9690e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(summary_text):\n",
    "    inputs = tokenizer(\n",
    "        summary_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = trainer(**inputs)\n",
    "\n",
    "    predicted_class_id = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return label_classes[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747ee2c-f68e-4ca0-9fbb-1ec4790a91ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfp]",
   "language": "python",
   "name": "conda-env-tfp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
